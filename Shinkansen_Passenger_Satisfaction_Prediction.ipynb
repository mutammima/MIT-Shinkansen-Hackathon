{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# \ud83d\ude82 Shinkansen Travel Experience - Passenger Satisfaction Prediction\n# \ud83d\udcda Prepared for Google Colab"}, {"cell_type": "code", "metadata": {}, "source": "# ---------------------------------------------\n# 1. Setup\n# ---------------------------------------------\n\n!pip install lightgbm xgboost catboost openpyxl\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntravel_train = pd.read_csv('/content/Traveldata_train.csv')\nsurvey_train = pd.read_csv('/content/Surveydata_train.csv')\ntravel_test = pd.read_csv('/content/Traveldata_test.csv')\nsurvey_test = pd.read_csv('/content/Surveydata_test.csv')\nsample_submission = pd.read_csv('/content/Sample_Submission.csv')"}, {"cell_type": "code", "metadata": {}, "source": "# ---------------------------------------------\n# 2. Merge Datasets\n# ---------------------------------------------\n\ntrain = pd.merge(travel_train, survey_train, on='ID')\ntest = pd.merge(travel_test, survey_test, on='ID')\n\nprint(f\"Train shape: {train.shape}\")\nprint(f\"Test shape: {test.shape}\")"}, {"cell_type": "code", "metadata": {}, "source": "# ---------------------------------------------\n# 3. Data Preprocessing\n# ---------------------------------------------\n\nmissing = train.isnull().mean() * 100\nmissing = missing[missing > 0].sort_values(ascending=False)\nprint(\"Missing values:\\n\", missing)\n\nfor col in train.columns:\n    if train[col].dtype == 'object':\n        train[col].fillna(train[col].mode()[0], inplace=True)\n        test[col].fillna(test[col].mode()[0], inplace=True)\n    else:\n        train[col].fillna(train[col].mean(), inplace=True)\n        test[col].fillna(test[col].mean(), inplace=True)\n\ncat_features = train.select_dtypes(include='object').columns\nle = LabelEncoder()\nfor col in cat_features:\n    train[col] = le.fit_transform(train[col])\n    test[col] = le.transform(test[col])"}, {"cell_type": "code", "metadata": {}, "source": "# ---------------------------------------------\n# 4. Feature Engineering\n# ---------------------------------------------\n\nX = train.drop(['Overall_Experience', 'ID'], axis=1)\ny = train['Overall_Experience']\nX_test = test.drop('ID', axis=1)\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nX_test = scaler.transform(X_test)"}, {"cell_type": "code", "metadata": {}, "source": "# ---------------------------------------------\n# 5. Model Building\n# ---------------------------------------------\n\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nlgb_params = {\n    'objective': 'binary',\n    'metric': 'accuracy',\n    'boosting_type': 'gbdt',\n    'learning_rate': 0.01,\n    'num_leaves': 31,\n    'max_depth': -1,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'random_state': 42,\n    'verbose': -1\n}\n\noof_preds = np.zeros(X.shape[0])\ntest_preds = np.zeros(X_test.shape[0])\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n    print(f\"Training fold {fold + 1}\")\n    X_train, X_val = X[train_idx], X[val_idx]\n    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n    train_data = lgb.Dataset(X_train, label=y_train)\n    val_data = lgb.Dataset(X_val, label=y_val)\n\n    model = lgb.train(lgb_params, train_data, num_boost_round=5000, \n                      valid_sets=[train_data, val_data], early_stopping_rounds=100, verbose_eval=500)\n\n    oof_preds[val_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n    test_preds += model.predict(X_test, num_iteration=model.best_iteration) / kf.n_splits\n\nfinal_oof = (oof_preds >= 0.5).astype(int)\nfinal_test = (test_preds >= 0.5).astype(int)\n\nprint(\"\\nCross-validation Accuracy:\", accuracy_score(y, final_oof))\nprint(\"Classification Report:\\n\", classification_report(y, final_oof))"}, {"cell_type": "code", "metadata": {}, "source": "# ---------------------------------------------\n# 6. Feature Importance\n# ---------------------------------------------\n\nlgb.plot_importance(model, max_num_features=20, importance_type='gain')\nplt.title(\"Feature Importance\")\nplt.show()"}, {"cell_type": "code", "metadata": {}, "source": "# ---------------------------------------------\n# 7. Submission\n# ---------------------------------------------\n\nsubmission = sample_submission.copy()\nsubmission['Overall_Experience'] = final_test\nsubmission.to_csv('final_submission.csv', index=False)\n\nprint(\"\\n\u2705 Submission file created: final_submission.csv\")"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 2}